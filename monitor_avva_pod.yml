---
- name: Monitor AVVA pod logs, restart on failure, create ServiceNow ticket if needed
  hosts: localhost
  connection: local
  gather_facts: no

  vars:
    # k8s / pod settings
    k8s_namespace: default
    pod_label: "app=avva-app"
    max_restarts: 3
    wait_ready_timeout: 120
    log_tail_lines: 200
    log_since: "5m"

    # failure detection (egrep -Ei)
    failure_regex: "error|failed|exception|panic|traceback"

    # ticketing
    ticket_on_failure: true
    ticket_api_url: "https://ascendiondigitalsolutionsdemo1.service-now.com/api/now/table/incident"

    # ServiceNow credentials: provide these as Job Template extra vars or via AWX credential mapping
    # sn_user: "svc_awx"        <-- supply in Job Template extra vars or credential
    # sn_pass: "REDACTED"       <-- supply in Job Template extra vars or credential

    ticket_payload:
      short_description: "AVVA pod failed after restarts"
      description: |
        Pod label: {{ pod_label }}
        Namespace: {{ k8s_namespace }}
        Attempts: {{ max_restarts }}
        Observed logs: "{{ last_failure_excerpt | default('n/a') }}"

  tasks:
    - name: Show which Azure env vars are present (non-sensitive)
      ansible.builtin.shell: |
        bash -lc 'for v in AZURE_CLIENT_ID AZURE_SECRET AZURE_TENANT AZURE_TENANT_ID AZURE_SUBSCRIPTION_ID; do
          if [ -n "${!v:-}" ]; then echo "$v=SET"; else echo "$v=NOT_SET"; fi
        done'
      register: azure_env_check
      changed_when: false

    - name: Debug azure env presence
      ansible.builtin.debug:
        var: azure_env_check.stdout_lines

    - name: Fail if AZURE_CLIENT_ID or AZURE_SECRET or AZURE_TENANT not set
      ansible.builtin.fail:
        msg: "Required Azure env vars missing. Attach Azure RM credential to job template."
      when: >
        (lookup('env','AZURE_CLIENT_ID') | default('')) == "" or
        (lookup('env','AZURE_SECRET')   | default('')) == "" or
        (lookup('env','AZURE_TENANT')   | default('')) == ""

    - name: Login to Azure using AWX-injected env vars
      ansible.builtin.shell: |
        bash -lc "az login --service-principal \
          --username \"$AZURE_CLIENT_ID\" \
          --password \"$AZURE_SECRET\" \
          --tenant \"$AZURE_TENANT\" >/dev/null"
      register: az_login
      failed_when: az_login.rc != 0
      changed_when: false

    - name: Get AKS credentials (merge into kubeconfig)
      ansible.builtin.shell: >
        bash -lc "az aks get-credentials --resource-group Azure_REG --name AVVA_aks --overwrite-existing"
      register: aks_creds
      failed_when: aks_creds.rc != 0
      changed_when: true

    - name: Find pod name matching label
      ansible.builtin.shell: >
        bash -lc "kubectl get pods -n {{ k8s_namespace }} -l '{{ pod_label }}' -o jsonpath='{.items[0].metadata.name}'"
      register: pod_get
      changed_when: false
      failed_when: pod_get.stdout | trim == ""

    - name: Set pod_name fact
      ansible.builtin.set_fact:
        pod_name: "{{ pod_get.stdout | trim }}"

    - name: Fetch latest logs for pod
      ansible.builtin.shell: >
        bash -lc "kubectl logs {{ pod_name }} -n {{ k8s_namespace }} --since={{ log_since }} --tail={{ log_tail_lines }} || true"
      register: pod_logs
      changed_when: false
      failed_when: false

    - name: Evaluate logs for failure pattern
      ansible.builtin.set_fact:
        failed_match: "{{ (pod_logs.stdout is search(failure_regex, ignorecase=True)) | bool }}"
        last_failure_excerpt: "{{ pod_logs.stdout[:400] }}"

    - name: Exit early if pod is healthy
      meta: end_play
      when: not failed_match

    - name: Restart pod up to max_restarts and check logs after each attempt
      ansible.builtin.shell: |
        set -euo pipefail
        NS="{{ k8s_namespace }}"; LABEL='{{ pod_label }}'; MAX={{ max_restarts }}; LOG_LINES={{ log_tail_lines }}; FAIL_PAT="{{ failure_regex }}"
        attempt=1; last_logs=""
        while [ "$attempt" -le "$MAX" ]; do
          echo "ATTEMPT=$attempt"
          POD=$(kubectl get pods -n "$NS" -l "$LABEL" -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || true)
          if [ -n "$POD" ]; then kubectl delete pod "$POD" -n "$NS" --wait=false || true; fi
          kubectl wait --for=condition=ready pod -l "$LABEL" -n "$NS" --timeout={{ wait_ready_timeout }}s || true
          NEWPOD=$(kubectl get pods -n "$NS" -l "$LABEL" -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || true)
          sleep 5
          last_logs=$(kubectl logs "$NEWPOD" -n "$NS" --tail="$LOG_LINES" 2>/dev/null || true)
          echo "$last_logs"
          echo "$last_logs" | egrep -Ei "$FAIL_PAT" >/dev/null 2>&1
          if [ $? -ne 0 ]; then echo "POD_HEALTHY_AFTER_RESTART"; exit 0; fi
          attempt=$((attempt+1))
        done
        echo "POD_STILL_FAILING_AFTER_RESTARTS"
        echo "$last_logs"
        exit 1
      register: restart_result
      changed_when: false
      failed_when: false

    - name: Determine final_failed and last excerpt
      ansible.builtin.set_fact:
        final_failed: "{{ 'POD_STILL_FAILING_AFTER_RESTARTS' in (restart_result.stdout | default('')) }}"
        last_failure_excerpt: "{{ (restart_result.stdout | default(''))[:400] }}"

    - name: Create ServiceNow ticket if still failing
      when: final_failed and ticket_on_failure
      ansible.builtin.uri:
        url: "{{ ticket_api_url }}"
        method: POST
        user: "{{ sn_user }}"
        password: "{{ sn_pass }}"
        force_basic_auth: yes
        status_code: [200,201]
        headers:
          Content-Type: "application/json"
        body_format: json
        body: "{{ ticket_payload }}"
      register: ticket_result
      failed_when: ticket_result.status not in [200,201]

    - name: Show ServiceNow response
      ansible.builtin.debug:
        var: ticket_result.json
      when: final_failed and ticket_on_failure

    - name: Final message
      ansible.builtin.debug:
        msg: "Done: final_failed={{ final_failed }} pod={{ pod_name }} excerpt='{{ last_failure_excerpt }}'"
